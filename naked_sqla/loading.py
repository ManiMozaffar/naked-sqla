from typing import Any, TypeVar

from sqlalchemy import exc as sa_exc
from sqlalchemy import util
from sqlalchemy.engine.cursor import CursorResult
from sqlalchemy.engine.result import ChunkedIteratorResult, Result, SimpleResultMetaData
from sqlalchemy.orm.context import QueryContext

_T = TypeVar("_T", bound=Any)
_O = TypeVar("_O", bound=object)
_new_runid = util.counter()


def instances(cursor: CursorResult[Any], context: QueryContext) -> Result[Any]:
    """Return a :class:`.Result` given an ORM query context.

    :param cursor: a :class:`.CursorResult`, generated by a statement
     which came from :class:`.ORMCompileState`

    :param context: a :class:`.QueryContext` object

    :return: a :class:`.Result` object representing ORM results

    .. versionchanged:: 1.4 The instances() function now uses
       :class:`.Result` objects and has an all new interface.

    """

    context.runid = _new_runid()

    if context.top_level_context:
        is_top_level = False
        context.post_load_paths = context.top_level_context.post_load_paths
    else:
        is_top_level = True
        context.post_load_paths = {}

    compile_state = context.compile_state
    filtered = compile_state._has_mapper_entities
    single_entity = (
        not context.load_options._only_return_tuples
        and len(compile_state._entities) == 1
        and compile_state._entities[0].supports_single_entity
    )

    try:
        (process, labels, extra) = list(
            zip(
                *[
                    query_entity.row_processor(context, cursor)
                    for query_entity in context.compile_state._entities
                ]
            )
        )

        if context.yield_per and (
            context.loaders_require_buffering or context.loaders_require_uniquing
        ):
            raise sa_exc.InvalidRequestError(
                "Can't use yield_per with eager loaders that require uniquing "
                "or row buffering, e.g. joinedload() against collections "
                "or subqueryload().  Consider the selectinload() strategy "
                "for better flexibility in loading objects."
            )

    except Exception:
        with util.safe_reraise():
            cursor.close()

    row_metadata = SimpleResultMetaData(labels, extra, _unique_filters=None)  #  type: ignore

    def chunks(size):  # type: ignore
        while True:
            yield_per = size

            context.partials = {}  # type: ignore

            if yield_per:
                fetch = cursor.fetchmany(yield_per)

                if not fetch:
                    break
            else:
                fetch = cursor._raw_all_rows()

            if single_entity:
                proc = process[0]  # type: ignore
                rows = [proc(row) for row in fetch]
            else:
                rows = [tuple([proc(row) for proc in process]) for row in fetch]  # type: ignore

            # if we are the originating load from a query, meaning we
            # aren't being called as a result of a nested "post load",
            # iterate through all the collected post loaders and fire them
            # off.  Previously this used to work recursively, however that
            # prevented deeply nested structures from being loadable
            if is_top_level:
                if yield_per:
                    # if using yield per, memoize the state of the
                    # collection so that it can be restored
                    top_level_post_loads = list(context.post_load_paths.items())

                while context.post_load_paths:
                    post_loads = list(context.post_load_paths.items())
                    context.post_load_paths.clear()
                    for path, post_load in post_loads:
                        post_load.invoke(context, path)

                if yield_per:
                    context.post_load_paths.clear()
                    context.post_load_paths.update(top_level_post_loads)  # type: ignore

            yield rows

            if not yield_per:
                break

    if context.execution_options.get("prebuffer_rows", False):
        # this is a bit of a hack at the moment.
        # I would rather have some option in the result to pre-buffer
        # internally.
        _prebuffered = list(chunks(None))

        def chunks(size):
            return iter(_prebuffered)

    result = ChunkedIteratorResult(
        row_metadata,
        chunks,
        source_supports_scalars=single_entity,
        raw=cursor,
        dynamic_yield_per=cursor.context._is_server_side,
    )

    # filtered and single_entity are used to indicate to legacy Query that the
    # query has ORM entities, so legacy deduping and scalars should be called
    # on the result.
    result._attributes = result._attributes.union(
        dict(filtered=filtered, is_single_entity=single_entity)
    )

    # # multi_row_eager_loaders OTOH is specific to joinedload.
    # if context.compile_state.multi_row_eager_loaders:

    #     def require_unique(obj):
    #         raise sa_exc.InvalidRequestError(
    #             "The unique() method must be invoked on this Result, "
    #             "as it contains results that include joined eager loads "
    #             "against collections"
    #         )

    #     result._unique_filter_state = (None, require_unique)

    if context.yield_per:
        result.yield_per(context.yield_per)

    return result
